{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hybridization.json from a directory of image files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a starfish json file from a directory of files and shows how to load the resulting data using starfish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.io import imread, imsave\n",
    "from collections import Counter, OrderedDict\n",
    "from typing import Mapping, Dict, List, Generator, Tuple\n",
    "\n",
    "from starfish.constants import Indices\n",
    "import hashlib\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_hash(filename: str) -> str:\n",
    "    \"\"\"return sha256 hash for file\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(filename, 'rb', buffering=0) as f:\n",
    "        for b in iter(lambda : f.read(128*1024), b''):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple experiment metadata object\n",
    "experiment_metadata = {\n",
    "    \"version\": \"0.0.0\",\n",
    "    \"hybridization_images\": \"hybridization.json\",\n",
    "    \"auxiliary_images\": {\n",
    "        \"nuclei\": \"nuclei.json\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a few methods to generate JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual execution block is in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exFISH_files_to_indices(glob_pattern: str, regex: str) \\\n",
    "        -> Generator[Tuple[str, Dict[Indices, int]], None, None]:\n",
    "    \"\"\"yield metadata parsed from the read name of a globbed directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    glob_pattern : str\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - For exFISH, imaging round is not used, so it is just always 1. \n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    Tuple[str, Dict[Indices, int]] : \n",
    "        tuple of filename and a dictionary that contains the tile metadata (channel, imaging round, and z-plane)\n",
    "    \"\"\"\n",
    "    files = glob.glob(glob_pattern)\n",
    "        \n",
    "    for f in files:\n",
    "        dir, basename = os.path.split(f)\n",
    "        raw_z, raw_channel = re.match(regex, basename).groups()\n",
    "        z = int(raw_z) - 1\n",
    "        channel = int(raw_channel) - 1\n",
    "        yield f, {Indices.CH: channel, Indices.ROUND: 0, Indices.Z: z}\n",
    "\n",
    "        \n",
    "def create_imaging_json(\n",
    "    files_to_indices_map: Dict[str, Dict[Indices, int]], default_tile_format='TIFF') \\\n",
    "        -> dict:\n",
    "    \"\"\"Creates a imaging json file that specifies how the TIFF files construct a 5-d image tensor\n",
    "    Parameters\n",
    "    ----------\n",
    "    files_to_indices_map : Generator[Tuple[str, Dict[Indices, int]], None, None]\n",
    "        map of file names, to the indices for that file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : \n",
    "        imaging json file in starfish v0.0.0 format\n",
    "        \n",
    "    \"\"\"\n",
    "    tiles = []\n",
    "    default_tile_shape = None\n",
    "    \n",
    "    for file_name, tile_indices in files_to_indices_map:\n",
    "        if default_tile_shape is None:\n",
    "            default_tile_shape = list(imread(file_name).shape)\n",
    "        hash_ = file_hash(file_name)\n",
    "        tiles.append(\n",
    "            {\n",
    "                \"coordinates\": {\n",
    "                    \"x\": [0, 0.0001],\n",
    "                    \"y\": [0, 0.0001],\n",
    "                    \"z\": [0, 0.0001],\n",
    "                },\n",
    "                \"indices\": {k.value: v for (k, v) in tile_indices.items()},\n",
    "                \"file\": os.path.basename(file_name),\n",
    "                \"sha256\": hash_\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # get tile shape\n",
    "    rounds = 1 + max(t[\"indices\"][Indices.ROUND] for t in tiles)\n",
    "    channels = 1 + max(t[\"indices\"][Indices.CH] for t in tiles)\n",
    "    z_planes = 1 + max(t[\"indices\"][Indices.Z] for t in tiles)\n",
    "\n",
    "    return {\n",
    "        \"version\": \"0.0.0\",\n",
    "        \"dimensions\": [\"x\", \"y\"] + list(k.value for k in tile_indices.keys()),\n",
    "        \"default_tile_shape\": default_tile_shape,\n",
    "        \"default_tile_format\": default_tile_format,\n",
    "        \"shape\": {\n",
    "            f\"{Indices.ROUND.value}\": rounds,\n",
    "            f\"{Indices.CH.value}\": channels,\n",
    "            f\"{Indices.Z.value}\": z_planes\n",
    "        },\n",
    "        \"tiles\": tiles\n",
    "    }\n",
    "\n",
    "# faked up codebook\n",
    "exFISH_codebook = [\n",
    "    {\n",
    "        \"codeword\": {'c': 0, 'h': 0, 'v': 1}, \n",
    "        \"target\": \"gene_1\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the starfish specification files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'40x_ROI1_YFP_488_ActB_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/YFP_brain_slice/fov_001/40x_ROI1_YFP_488_ActB\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'40x_ROI2_YFP_488_ActB_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/YFP_brain_slice/fov_002/40x_ROI2_YFP_488_ActB\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'40x_A1_TFRC_1_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/cultured_cells/041216_After_006/fov_001/40x_A1_TFRC_1_z\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'40x_A2_ActB_3_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/cultured_cells/041216_After_006/fov_002/40x_A2_ActB_3_z\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'40x_A3_Top2A_5_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/cultured_cells/041216_After_006/fov_003/40x_A3_Top2A_5_z\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'60x_A2_After_EEF2_TxR_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/cultured_cells/040216_After_006/fov_001/60x_A2_After_EEF2_TxR_z\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'60x_A2_After_UBC_647_z([0-9]{3})_c([0-9]{3}).tif')\n",
    "\n",
    "DIRECTORY = os.path.expanduser(\"~/google_drive/starfish/data/exFISH/cultured_cells/040216_After_006/fov_002/60x_A2_After_UBC_647_z\")\n",
    "\n",
    "# generate maps of filenames to tile metadata\n",
    "nuclei_indices = exFISH_files_to_indices(DIRECTORY + '*c002*.tif', regex)\n",
    "gene_indices = exFISH_files_to_indices(DIRECTORY + '*c001*.tif', regex)\n",
    "\n",
    "# create the hybridization json\n",
    "hyb_json = create_imaging_json(gene_indices)\n",
    "\n",
    "# ... and the nuclei json\n",
    "nuclei_json = create_imaging_json(nuclei_indices)\n",
    "\n",
    "# write everything to disk\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'hybridization.json'), 'w') as f:\n",
    "    json.dump(hyb_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'nuclei.json'), 'w') as f:\n",
    "    json.dump(nuclei_json, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'experiment.json'), 'w') as f:\n",
    "    json.dump(experiment_metadata, f)\n",
    "with open(os.path.join(os.path.dirname(DIRECTORY), 'codebook.json'), 'w') as f:\n",
    "    json.dump(exFISH_codebook, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read the data into starfish, and below we display the 1st channel (CY3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.io import Stack\n",
    "experiment_json = os.path.join(os.path.dirname(DIRECTORY), 'experiment.json')\n",
    "s = Stack.from_experiment_json(experiment_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45425946023f498cbdcb328a4ceaa007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='plane_index', max=28), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', FutureWarning)\n",
    "    s.image.show_stack({Indices.CH: 0}, rescale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
